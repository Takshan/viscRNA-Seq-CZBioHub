#!/usr/bin/env python
'''
viscRNA-Seq pipeline local script.

This script runs on the newly allocated EC2 instance as directed by the viscrna-seq-pipeline script and does the heavy lifting.
'''
import os
import sys
import subprocess as sp
import argparse


class Pipeline:
    def __init__(
            self,
            input_data_path,
            input_samplesheet_path,
            output_path,
            output_gdrive_path,
            dataset_id,
            ):

        self.input_data_path = input_data_path
        self.input_samplesheet_path = input_samplesheet_path
        self.output_path = output_path
        self.output_gdrive_path = output_gdrive_path
        self.dataset_id = dataset_id

    def get_data(self, path):
        if path.startswith('s3://'):
            return self.get_data_s3(path)
        elif path.startswith('http://') or path.startswith('https://'):
            return self.get_data_url(path)
        else:
            raise ValueError('Type of data source not recognized: {:}'.format(path))

    def unpack_data(self, path):
        parent = os.path.dirname(path)
        if parent == '':
            parent = '.'
        fn = os.path.basename(path)

        if fn.endswith('.tar.gz') or fn.endswith('.tar.xz'):
            sp.run(' '.join([
                'tar', '-xf', path, '-C', parent,
                ]),
                shell=True,
                check=True)
        else:
            raise ValueError('Compressed format not supported: {:}'.format(
                fn.split('.')[-1]))

        os.remove(path)

    def get_data_s3(self, url):
        fn = url.split('/')[-1]
        sp.run(' '.join([
            'aws', 's3', 'cp',
            url, fn,
            ]),
            shell=True,
            check=True,
            )

    def get_data_url(self, url):
        sp.run(' '.join([
            'wget', url,
            ]),
            shell=True,
            check=True,
            )

    def __call__(self):
        print('RUN PIPELINE')
        print('Get data')
        self.get_data(self.input_data_path)
        self.input_data_path = os.path.basename(self.input_data_path)

        print('Unpack data')
        self.unpack_data(self.input_data_path)
        self.input_data_path = '.'.join(self.input_data_path.split('.')[:-2])

        print('Get samplesheet')
        self.get_data(self.input_samplesheet_path)
        self.input_samplesheet_path = os.path.basename(self.input_samplesheet_path)

        print('Make fastq')
        os.makedirs('/data/fastq', exist_ok=True)
        sp.run(' '.join([
            'cellranger',
            'mkfastq',
            '--id={:}'.format(self.dataset_id),
            '--run={:}'.format(self.input_data_path),
            '--samplesheet={:}'.format(self.input_samplesheet_path),
            '--output-dir=/data/fastq'.format(self.dataset_id),
            ]),
            shell=True,
            check=True)

        print('Count genes')
        sp.run(' '.join([
            'cellranger',
            'count'
            '--id='+self.dataset_id,
            '--transcriptome=/assets/references/mouse_and_mCMV',
            '--fastqs=/data/fastq',
            '--sample='+self.dataset_id,
            '--expect-cells=5000',
            ]),
            shell=True,
            check=True)
        # NOTE: output goes in a subfolder of the cwd called like the sample:
        # $HOME/<self.dataset_id>/outs/possorted_genome_bam.bam
        # $HOME/<self.dataset_id>/outs/filtered_gene_bc_matrices_h5.h5
        # see: https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/overview

        print('Transfer output to S3')
        sp.run(' '.join([
            'aws', 's3', 'cp',
            '{:}/{:}'.format(
                os.getenv('HOME'),
                self.dataset_id),
            's3://viscrna-seq/data/{:}/'.format(
                self.dataset_id),
            '--recursive',
            ]),
            check=True,
            shell=True)

        print('Transfer count table to GDrive')
        # TODO

        print('Done')



if __name__ == '__main__':

    pa = argparse.ArgumentParser(description='''viscRNA-Seq pipeline''')
    pa.add_argument(
            '--input-data', required=True,
            help='The location of the raw reads')
    pa.add_argument(
            '--input-samplesheet', required=True,
            help='The location of the samplesheet')
    pa.add_argument(
            '--output', required=True,
            help='The location of the output S3 bucket')
    pa.add_argument(
            '--output-gdrive', required=False, default=None,
            help='The location on GoogleDrive where to store the count table')
    pa.add_argument(
            '--id', required=True,
            help='Sets a unique ID for the dataset, for record keeping')

    args = pa.parse_args()

    print('Ready the pipeline')
    pipe = Pipeline(
            input_data_path=args.input_data,
            input_samplesheet_path=args.input_samplesheet,
            output_path=args.output,
            output_gdrive_path=args.output_gdrive,
            dataset_id=args.id,
            )

    print('Run the pipeline')
    pipe()
